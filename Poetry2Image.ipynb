{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Poetry2Image.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYFUMuo6YPXe","executionInfo":{"status":"ok","timestamp":1633448547613,"user_tz":-60,"elapsed":38534,"user":{"displayName":"Hexun Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5AD3VaSu_tNCNfPS8H_GXKkhxh-UBUPQYn_CH=s64","userId":"16950624869085310764"}},"outputId":"641c973b-07d5-445c-b569-1a78b438d3d5"},"source":["# Connect with your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive') \n","!rm -rf /content/sample_data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"3Wh0muHiMHI8"},"source":["# Setup required environment"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPVoEblRQVmT","executionInfo":{"status":"ok","timestamp":1633448571827,"user_tz":-60,"elapsed":22745,"user":{"displayName":"Hexun Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5AD3VaSu_tNCNfPS8H_GXKkhxh-UBUPQYn_CH=s64","userId":"16950624869085310764"}},"outputId":"68e51bb0-0252-4326-8200-5436811c6cea"},"source":["# Install the required environment\n","!pip install wget\n","!pip install git+https://github.com/openai/CLIP.git\n","!pip install DALL-E"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=553cd247808c201e17329e26a9b48899a5f4b64c9b70676cf1933d68cc0d1076\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-l3ick2ji\n","  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-l3ick2ji\n","Collecting ftfy\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.10.0+cu102)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.19.5)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n","Building wheels for collected packages: clip, ftfy\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369090 sha256=3240624e179642e97fd41db4080b738f894e7b14474c50a88ebc856cfda88850\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-eo3o0c96/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=35cc0dd7e2acd4a52a2ee5ec142b2e08465f0848f3556156e6962b694d3362b9\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","Successfully built clip ftfy\n","Installing collected packages: ftfy, clip\n","Successfully installed clip-1.0 ftfy-6.0.3\n","Collecting DALL-E\n","  Downloading DALL_E-0.1-py3-none-any.whl (6.0 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from DALL-E) (7.1.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from DALL-E) (0.10.0+cu102)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from DALL-E) (3.6.4)\n","Collecting blobfile\n","  Downloading blobfile-1.2.5-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 1.8 MB/s \n","\u001b[?25hCollecting mypy\n","  Downloading mypy-0.910-cp37-cp37m-manylinux2010_x86_64.whl (21.5 MB)\n","\u001b[K     |████████████████████████████████| 21.5 MB 45.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from DALL-E) (1.19.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from DALL-E) (1.9.0+cu102)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from DALL-E) (2.23.0)\n","Collecting urllib3~=1.25\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 61.6 MB/s \n","\u001b[?25hCollecting xmltodict~=0.12.0\n","  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n","Collecting pycryptodomex~=3.8\n","  Downloading pycryptodomex-3.10.4-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 40.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.7/dist-packages (from blobfile->DALL-E) (3.0.12)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from mypy->DALL-E) (0.10.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from mypy->DALL-E) (3.7.4.3)\n","Collecting mypy-extensions<0.5.0,>=0.4.3\n","  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n","Collecting typed-ast<1.5.0,>=1.4.0\n","  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n","\u001b[K     |████████████████████████████████| 743 kB 47.7 MB/s \n","\u001b[?25hRequirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (1.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (57.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (1.10.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (0.7.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (1.15.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (21.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E) (8.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->DALL-E) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->DALL-E) (3.0.4)\n","Collecting urllib3~=1.25\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 65.2 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->DALL-E) (2021.5.30)\n","Installing collected packages: xmltodict, urllib3, typed-ast, pycryptodomex, mypy-extensions, mypy, blobfile, DALL-E\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed DALL-E-0.1 blobfile-1.2.5 mypy-0.910 mypy-extensions-0.4.3 pycryptodomex-3.10.4 typed-ast-1.4.3 urllib3-1.25.11 xmltodict-0.12.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"sVnKdT2UL8R0"},"source":["# Import packages and Set the parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ooIIT8kYglx","executionInfo":{"status":"ok","timestamp":1633449175236,"user_tz":-60,"elapsed":448,"user":{"displayName":"Hexun Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5AD3VaSu_tNCNfPS8H_GXKkhxh-UBUPQYn_CH=s64","userId":"16950624869085310764"}},"outputId":"d1a3f111-c60b-44d5-9806-9616e5c901d7"},"source":["%cd '/content/drive/MyDrive/Portfolio/Poem2Image'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Portfolio/Poem2Image\n"]}]},{"cell_type":"code","metadata":{"id":"iHehVCfd1J0S"},"source":["# Import packages\n","from dall_e import map_pixels, unmap_pixels, load_model\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import random\n","import clip\n","import os\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Set the parameters\n","image_size = 512\n","epochs = 300"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-VptmBsL16Q"},"source":["# Load the CLIP model"]},{"cell_type":"code","metadata":{"id":"YngKuUF3fofG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633448596868,"user_tz":-60,"elapsed":19327,"user":{"displayName":"Hexun Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5AD3VaSu_tNCNfPS8H_GXKkhxh-UBUPQYn_CH=s64","userId":"16950624869085310764"}},"outputId":"a916bc91-ec8d-4ebd-93fd-8b90c6284ae5"},"source":["# Load the pre-trained CLIP model\n","perceptor, preprocess   = clip.load('ViT-B/32')\n","perceptor               = perceptor.eval()\n","\n","# Load the pre-trained descrete VAE model\n","model = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", 'cuda').eval()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 338M/338M [00:05<00:00, 68.5MiB/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"c8W8aDBeXFAM"},"source":["#Load Poetry"]},{"cell_type":"code","metadata":{"id":"7P0RW-jIXLT5"},"source":["# Load poems\n","poems = []\n","with open('./poetry_EN.txt') as inputfile:\n","    for line in inputfile:\n","      poems.append(line.strip())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6yA5-FB8LnWI"},"source":["# Init and Training Process"]},{"cell_type":"code","metadata":{"id":"VFul4x39eY1d"},"source":["# The Normalization of the images\n","nom = T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n","\n","class Pars(nn.Module):\n","    '''\n","    The class used to generate the random latents.\n","    '''\n","    def __init__(self):\n","        super(Pars, self).__init__()\n","        self.normu = nn.Parameter(torch.zeros(1, 8192, 64, 64).cuda())\n","\n","    def forward(self):\n","        normu = F.gumbel_softmax(self.normu.view(1, 8192, -1), dim=-1, tau = 2).view(1, 8192, 64, 64)\n","        return normu\n","\n","\n","def pad_augs(image):\n","    '''\n","    The class used to padding images\n","    '''\n","    pad = random.randint(1,50)\n","    pad_px = random.randint(10,90)/100\n","    pad_py = random.randint(10,90)/100\n","    pad_dims = (int(pad*pad_px), pad-int(pad*pad_px), int(pad*pad_py), pad-int(pad*pad_py))\n","    return F.pad(image, pad_dims, \"constant\", 1)\n","\n","def computing_loss(model, lats, image_size, perceptor, percep, tokenizedtxt):\n","    '''\n","    The class used to generate images and calculate loss function\n","    '''\n","    cutn = 32\n","    zs = lats()\n","    out = unmap_pixels(torch.sigmoid(model(zs)[:, :3].float()))\n","\n","    p_s = []\n","    for ch in range(cutn):\n","        size = int(image_size*torch.zeros(1,).normal_(mean=.39, std=.865).clip(.362, .7099))\n","        offsetx = torch.randint(0, image_size - size, ())\n","        offsety = torch.randint(0, image_size - size, ())\n","        apper = out[:, :, offsetx:offsetx + size, offsety:offsety + size]\n","        apper = pad_augs(apper)\n","        apper = F.interpolate(apper, (224, 224), mode='nearest')\n","        p_s.append(apper)\n","\n","    into = torch.cat(p_s, 0)\n","    into = nom((into + 1) / 2)\n","    iii = perceptor.encode_image(into)\n","\n","    return [-100*torch.cosine_similarity(percep, iii).view(-1, 1).T.mean(), zs, out]\n","\n","def train(i, model, lats, image_size, perceptor, percep, optimizer, tokenizedtxt):\n","    '''\n","    The class is used to train the model\n","    '''\n","    output = computing_loss(model, lats, image_size, perceptor, percep, tokenizedtxt)\n","    \n","    # the loss of models\n","    loss = output[0]\n","    loss = loss.mean()\n","    zs = output[1]\n","    img  = output[2].cpu()\n","\n","    # updata the parameters\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    '''\n","    # show plots during the iteration times\n","    if(i % 25 == 0):\n","      print(i)\n","      img = img[0].detach().numpy()\n","      img = np.transpose(img, (1, 2, 0))\n","      im = Image.fromarray((img * 255).astype(np.uint8))\n","      display(im)\n","      #im.save('./test/test'+str(iter)+'.jpg')'''\n","    \n","    return zs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80hB9leQG4h1"},"source":["# Main Loop"]},{"cell_type":"code","metadata":{"id":"1usvcgy7tAxi"},"source":["# The iteration for each poem in the dataset\n","for iter in range(0, len(poems)):\n","  text = poems[iter]\n","\n","  # load the latents\n","  lats = Pars().cuda()\n","  par     = [lats.normu]\n","  lr      = .05\n","  \n","  optimizer = torch.optim.Adam(par, lr)\n","  txt = clip.tokenize(text[:250])\n","  percep = perceptor.encode_text(txt.cuda()).detach().clone()\n","\n","  # training Loop\n","  for i in range(epochs):\n","      zs = train(i, model, lats, image_size, perceptor, percep, optimizer, txt)\n","\n","  # generate images\n","  with torch.no_grad():\n","      img = unmap_pixels(torch.sigmoid(model(zs)[:, :3]).cpu().float())\n","      img = np.array(img[0])\n","      img = np.transpose(img, (1, 2, 0))\n","      im = Image.fromarray((img * 255).astype(np.uint8))\n","      display(im)\n","      im.save('./test/output'+str(iter)+'.jpg')\n","      print(text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e64lhIubG8kG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cRdDIEbFG8uP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_P8eMnlG8wY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OAexUwj-Hjn9"},"source":["# Reference:\n","@ Phil Wang, BigSleep, https://github.com/lucidrains/big-sleep\n","\n","@ Yannic Kilcher, CLIP Music Video, https://github.com/yk/clip_music_video\n","\n","@ OpenAI, DALLE, https://github.com/openai/dall-e\n","\n","@ OpenAI, CLIP, https://github.com/openai/CLIP"]}]}